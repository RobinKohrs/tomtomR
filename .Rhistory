print(r)
# the grid cell
row = grid[r, ] %>% st_transform(4326)
if(!lengths(st_intersects(row, data_per_segment)) > 0){
print("no intersection")
return(NA)
}
# get all the segments within
segments = data_per_segment[row, ]
mean_ratio = mean(segments$mean_ratio)
row[["mean_ratio"]] = mean_ratio
})
a = bind_rows(grid_ratios)
is.na(grid_ratios)
grid_ratios_no_na = grid_ratios[!is.na(grid_ratios)]
# create the mean grid ----------------------------------------------------
mean_grid = bind_rows(grid_ratios_no_na)
grid_ratios_no_na
# for each grid cell get the mean ratio ---------------------------------
grid_ratios = map(seq_along(1:nrow(grid)[50:70]), function(r){
print(r)
# the grid cell
row = grid[r, ] %>% st_transform(4326)
if(!lengths(st_intersects(row, data_per_segment)) > 0){
print("no intersection")
return(NA)
}
# get all the segments within
segments = data_per_segment[row, ]
mean_ratio = mean(segments$mean_ratio)
row[["mean_ratio"]] = mean_ratio
row
})
# for each grid cell get the mean ratio ---------------------------------
grid_ratios = map(seq_along(1:nrow(grid))[50:70], function(r){
print(r)
# the grid cell
row = grid[r, ] %>% st_transform(4326)
if(!lengths(st_intersects(row, data_per_segment)) > 0){
print("no intersection")
return(NA)
}
# get all the segments within
segments = data_per_segment[row, ]
mean_ratio = mean(segments$mean_ratio)
row[["mean_ratio"]] = mean_ratio
row
})
grid_ratios
grid_ratios_no_na = grid_ratios[!is.na(grid_ratios)]
# create the mean grid ----------------------------------------------------
mean_grid = bind_rows(grid_ratios_no_na)
mean_grid
# for each grid cell get the mean ratio ---------------------------------
grid_ratios = map(seq_along(1:nrow(grid)), function(r){
print(r)
# the grid cell
row = grid[r, ] %>% st_transform(4326)
if(!lengths(st_intersects(row, data_per_segment)) > 0){
print("no intersection")
return(NA)
}
# get all the segments within
segments = data_per_segment[row, ]
mean_ratio = mean(segments$mean_ratio)
row[["mean_ratio"]] = mean_ratio
row
})
grid_ratios_no_na = grid_ratios[!is.na(grid_ratios)]
# create the mean grid ----------------------------------------------------
mean_grid = bind_rows(grid_ratios_no_na)
mean_grid
mapview(mean_grid, zcol="mean_ratio")
mapview(mean_grid, zcol="mean_ratio") + mapview(data_per_segment)
sum(is.na(mean_grid$mean_ratio))
# remove the NAs ----------------------------------------------------------
mean_grid_no_na = mean_grid %>%
filter(!is.na(mean_ratio))
# remove the NAs ----------------------------------------------------------
mean_grid_no_na = mean_grid %>%
filter(!is.na(mean_ratio)) %>%
mutate(id = row_number())
mean_grid
# geo ---------------------------------------------------------------------
op_geo = makePath(here("output/data/dw/grid/grid_geo.geojson"))
unlink(op_geo)
write_sf(mean_grid_no_na, op_geo)
# geo ---------------------------------------------------------------------
op_geo = makePath(here("output/data/dw/grid/grid_geo.geojson"))
unlink(op_geo)
write_sf(mean_grid_no_na %>% select(id), op_geo)
# data --------------------------------------------------------------------
op_data = makePath(here("output/data/dw/grid/grid_data.csv"))
mean_grid_no_na %>%
st_drop_geometry() %>%
write_csv(op_data)
op_data
mean_grid_no_na$mean_ratio %>% summary
# n classes
n_stops = 9
# colors
colors = scico::scico(n_stops+2, palette="vik") %>% rev()
colors[6] = "lightgrey"
# variable for binning the data
var = "mean_ratio"
data = mean_grid_no_na
# n classes
n_stops = 9
# colors
colors = scico::scico(n_stops+2, palette="vik") %>% rev()
colors[6] = "lightgrey"
# variable for binning the data
var = "mean_ratio"
#  equally spaced bins
data_extent = c(min(data[[var]], na.rm=T), max(data[[var]], na.rm=T))
data_extent_min = -max(abs(round(data_extent)))
data_extent_max = max(abs(round(data_extent)))
data_extent
breaks = seq(from=0.85, to=1.15, length.out=n_stops + 1)
breaks
# labels
labels = imap_chr(breaks, function(., idx) {
paste0(round(breaks[idx],1), " - ", round(breaks[idx + 1],1))
}) %>% .[1:length(.) - 1]
first_label = " < -0.5"
first_label = " < -0.85"
last_label = "> 1.15"
labels = c(first_label, labels, last_label)
labels
data
# assign data to classes
data %>%
filter(if_all({{var}}, ~!is.na(.x))) %>%
mutate(
class = findInterval(!!sym(var), breaks),
classname = labels[class+1],
color = colors[class+1]
) %>%
group_by(class, classname, color) %>%
summarise() %>%
mutate("stroke-width" = 2.5) -> data_colored
data_colored
# assign data to classes
data %>%
filter(if_all({{var}}, ~!is.na(.x))) %>%
mutate(
class = findInterval(!!sym(var), breaks),
classname = labels[class+1],
color = colors[class+1]
) %>%
group_by(class, classname, color) %>%
summarise() -> data_colored
data_colored
op_locator = makePath(here("output/data/dw/grid/locator_grid.geojson"))
unlink(op_locator)
write_sf(data_colored, op_locator)
# assign data to classes
data %>%
filter(if_all({{var}}, ~!is.na(.x))) %>%
mutate(
class = findInterval(!!sym(var), breaks),
classname = labels[class+1],
color = colors[class+1],
opacity = 90
) -> data_colored
op_locator = makePath(here("output/data/dw/grid/locator_grid.geojson"))
unlink(op_locator)
write_sf(data_colored, op_locator)
library(tidyverse)
library(here)
library(glue)
library(sf)
library(rajudas)
library(jsonlite)
library(tidygeocoder)
# path to segment data ----------------------------------------------------
path_data_segments = here("output/data/dw/full_area_analysis/per_segment_mean_diff_ratio.geojson")
# data per segment ---------------------------------------------------------
data_per_segment = read_sf(path_data_segments)
# variable to use ---------------------------------------------------------
var = "mean_ratio"
# top and flop segment centroids ------------------------------------------------------------
top_flop_centroids = data_per_segment %>%
filter(!is.na(!!sym(var))) %>%
arrange(mean_ratio) %>%
slice(c(1, nrow(.))) %>%
st_centroid() %>%
st_as_sf() %>%
select(name=streetName)
# adresses ----------------------------------------------------------------
adresses = list(list(
name = "Flughafen",
coords = c(53.62591092417195, 10.00400790583759)
),
list(
name = "Elbbrücken",
coords = c(53.538633176280754, 10.03127604254123)
))
pois = map(adresses, function(a) {
list(name = a$name,
x = a$coords[2],
y = a$coords[1])
}) %>% bind_rows() %>% st_as_sf(coords = c("x", "y"), crs = 4326)
# bind all together -------------------------------------------------------
all_highlights = bind_rows(top_flop_centroids, pois) %>%
mutate(
icon="circle-out-2",
"stroke-width" = 2,
"fill-opacity" = 0,
scale = .3,
"text-bold" = 1,
anchor = case_when(
name == "Flughafen" ~ "top-left",
name == "Überseering" ~ "top-right",
name == "Reeperbahn" ~ "bottom-left",
name == "Elbbrücken" ~ "bottom-right",
)
)
# write out ---------------------------------------------------------------
op_highlight_overviews = makePath(here("output/data/dw/full_area_analysis/highlight_overview_maps.geojson"))
unlink(op_highlight_overviews)
write_sf(all_highlights, op_highlight_overviews)
all_highlights
library(tidyverse)
library(here)
library(glue)
library(sf)
library(rajudas)
library(jsonlite)
# paths -------------------------------------------------------------------
dir(here("data_raw/sandtorkai/"), ".*\\.geojson$", recursive = T, full.names = T)
p = paths_geojsons[[1]]
# paths -------------------------------------------------------------------
paths_geojsons = dir(here("data_raw/sandtorkai/"), ".*\\.geojson$", recursive = T, full.names = T)
p = paths_geojsons[[1]]
p
paths_geojsons
basename(p)
basename(p) %>% janitor::make_clean_names()
dirname(p)
dirname(p) %>% basename()
parentdir = dirname(p) %>% basename()
p = paths_geojsons[4]
clean_name = basename(p) %>% janitor::make_clean_names()
clean_name
parentdir = dirname(p) %>% basename()
parentdir
str_detect(parentdir, "2020")
map(paths_geojsons, function(p){
clean_name = basename(p) %>% janitor::make_clean_names()
parentdir = dirname(p) %>% basename()
kartenversion = "2018"
if(str_detect(parentdir, "2020")){
kartenversion = "2020"
}
if(str_detect(parentdir, "2022")){
kartenversion = "2022"
}
print(kartenversion)
})
# read data
d = read_sf(p)
d
devtools::load_all()
d_clean = clean_full_area_data(d)
d_clean
plot(d_clean[0])
p
p
d
df = d
dim(df)
df$segmentTimeResults
df %>%
filter(!is.na(segmentTimeResults)) %>%
mutate(d = map(segmentTimeResults, function(c) {
fromJSON(c) %>% as.data.frame()
})) %>% unnest(d)
df %>%
filter(!is.na(segmentTimeResults)) %>%
mutate(d = map(segmentTimeResults, function(c) {
fromJSON(c) %>% as.data.frame()
})) %>% unnest(d) %>% View
df %>%
filter(!is.na(segmentTimeResults)) %>%
mutate(d = map(segmentTimeResults, function(c) {
fromJSON(c) %>% as.data.frame()
})) %>% unnest(d) %>% n_distinct(segmentId)
df %>%
filter(!is.na(segmentTimeResults)) %>%
mutate(d = map(segmentTimeResults, function(c) {
fromJSON(c) %>% as.data.frame()
})) %>% unnest(d) %>% pull(segmentId)
df %>%
filter(!is.na(segmentTimeResults)) %>%
mutate(d = map(segmentTimeResults, function(c) {
fromJSON(c) %>% as.data.frame()
})) %>% unnest(d) %>% pull(segmentId) %>% unique
df %>%
filter(!is.na(segmentTimeResults)) %>%
mutate(d = map(segmentTimeResults, function(c) {
fromJSON(c) %>% as.data.frame()
})) %>% unnest(d) %>%
select(
segmentId,
streetName,
speedLimit,
frc,
distance,
harmonicAverageSpeed:speedPercentiles
) -> d_clean
d_clean %>% group_by(segmentId) %>% filter(cur_group_id() == 1)
d_clean %>% group_by(segmentId) %>% filter(cur_group_id() == 1) %>% glimpse
library(tidyverse)
library(here)
library(glue)
library(sf)
library(rajudas)
library(jsonlite)
library(rmapshaper)
devtools::load_all()
# paths to data -----------------------------------------------------------
path_rush = here("data_raw/geo_full_area/rush_hour_combined_mor_eve/rushour.geojson")
path_avg = here("data_raw/geo_full_area/average/avg_all_times.geojson")
data_rush_raw = st_read(path_rush)
df = data_rush_raw
dim(df)
df %>%
filter(!is.na(segmentTimeResults)) %>%
mutate(d = map(segmentTimeResults, function(c) {
fromJSON(c) %>% as.data.frame()
})) %>% unnest(d) %>%
select(
segmentId,
streetName,
speedLimit,
frc,
distance,
harmonicAverageSpeed:speedPercentiles
) -> d_clean
dim(d_clean)
# read data
d = read_sf(p)
df = d
df %>%
filter(!is.na(segmentTimeResults)) %>%
mutate(d = map(segmentTimeResults, function(c) {
fromJSON(c) %>% as.data.frame()
})) %>% unnest(d) %>%
select(
segmentId,
streetName,
speedLimit,
frc,
distance,
harmonicAverageSpeed:speedPercentiles
) -> d_clean
d_clean %>% group_by(segmentId) %>% filter(cur_group_id() == 1) %>% glimpse
op_rush_clean = makePath(here("data_raw/geo_full_area/rush_hour_combined_mor_eve/clean_rushhour.geojson"))
op_rush_clean = makePath(here("data_raw/geo_full_area/rush_hour_combined_mor_eve/clean_rushhour.geojson"))
op_avg_clean = makePath(here("data_raw/geo_full_area/rush_hour_combined_mor_eve/clean_avg.geojson"))
data_rush %>% glimpse
# paths to data -----------------------------------------------------------
path_rush = here("data_raw/geo_full_area/rush_hour_combined_mor_eve/rushour.geojson")
path_avg = here("data_raw/geo_full_area/average/avg_all_times.geojson")
data_rush_raw = st_read(path_rush)
data_avg_raw = st_read(path_avg)
# save geo data -----------------------------------------------------------
data_geo = data_rush_raw %>% select(segmentId)
# clean the data ----------------------------------------------------------
# unnest the json column, add a time variable, and remove the geometry for now
data_rush = clean_full_area_data(data_rush_raw) %>% mutate(time="rush") %>% st_drop_geometry()
data_avg = clean_full_area_data(data_avg_raw) %>% mutate(time="avg") %>% st_drop_geometry()
data_rush %>% glimpse
op_rush_clean = makePath(here("data_raw/geo_full_area/rush_hour_combined_mor_eve/clean_rushhour.gpkg"))
op_avg_clean = makePath(here("data_raw/geo_full_area/rush_hour_combined_mor_eve/clean_avg.gpkg"))
data_rush %>% select(where(!is.list))
data_rush %>% select(where(is.numeric))
data_rush %>% select(where(function(x) ~!is.list(x)))
typeof(data_rush$speedPercentiles)
data_rush %>% select(where(is.list))
data_rush %>% select(where(!is.list))
data_rush %>% select(where(~!is.list(.x)))
op_rush_clean = makePath(here("data_raw/geo_full_area/rush_hour_combined_mor_eve/clean_rushhour.gpkg"))
write_sf(data_rush %>% select(where(~!is.list(.x))), op_rush_clean)
write_sf(data_avg %>% select(where(~!is.list(.x))), op_avg_clean)
op_rush_clean = makePath(here("data_raw/geo_full_area/rush_hour_combined_mor_eve/clean_rushhour.gpkg"))
op_avg_clean = makePath(here("data_raw/geo_full_area/rush_hour_combined_mor_eve/clean_avg.gpkg"))
write_sf(data_rush %>% select(where(~!is.list(.x))), op_rush_clean)
write_sf(data_avg %>% select(where(~!is.list(.x))), op_avg_clean)
# write out clean data
op_rush_clean = makePath(here("data_raw/geo_full_area/rush_hour_combined_mor_eve/clean_rushhour.gpkg"))
op_avg_clean = makePath(here("data_raw/geo_full_area/average//clean_avg.gpkg"))
write_sf(data_rush %>% select(where(~!is.list(.x))), op_rush_clean)
write_sf(data_avg %>% select(where(~!is.list(.x))), op_avg_clean)
data_rush %>% select(where(~!is.list(.x))
data_rush %>% select(where(~!is.list(.x)))
data_rush
# clean the data ----------------------------------------------------------
# unnest the json column, add a time variable, and remove the geometry for now
data_rush = clean_full_area_data(data_rush_raw) %>% mutate(time="rush")
data_avg = clean_full_area_data(data_avg_raw) %>% mutate(time="avg")
# write out clean data
op_rush_clean = makePath(here("data_raw/geo_full_area/rush_hour_combined_mor_eve/clean_rushhour.gpkg"))
op_avg_clean = makePath(here("data_raw/geo_full_area/average//clean_avg.gpkg"))
write_sf(data_rush %>% select(where(~!is.list(.x))), op_rush_clean)
write_sf(data_avg %>% select(where(~!is.list(.x))), op_avg_clean)
library(tidyverse)
library(here)
library(glue)
library(sf)
library(rajudas)
library(jsonlite)
grid
library(tidyverse)
library(here)
library(glue)
library(sf)
library(rajudas)
library(jsonlite)
devtools::load_all()
# params ------------------------------------------------------------------
area_selected = "urban"
value_column = "yearTravelTimePerKm"
output_path = here(makePath("output/data/dw/year_avg_travel_time_10km.csv"))
# data on german cities --------------------------------------------------
data = tomtomR::data_tomtom
data
100 * 10
100 * 10 / 60
# params ------------------------------------------------------------------
area_selected = "urban"
value_column = "yearTravelTimePerKm"
output_path = here(makePath("output/data/dw/year_avg_travel_time_10km.csv"))
# data on german cities --------------------------------------------------
data = tomtomR::data_tomtom
# get the data for each year ----------------------------------------------
data_wide = data %>%
filter(area == {{area_selected}}) %>%
select(year, area, city, country, all_of(value_column)) %>%
pivot_wider(names_from = "year",
values_from = all_of(value_column))
data_wide
data_wide %>% filter(city=="Hamburg")
# data on german cities --------------------------------------------------
data = tomtomR::data_tomtom
# get the data for each year ----------------------------------------------
data_wide = data %>%
filter(area == {{area_selected}}) %>%
select(year, area, city, country, all_of(value_column)) %>%
pivot_wider(names_from = "year",
values_from = all_of(value_column))
data_wide
data_wide %>% filter(city=="Hamburg")
library(tidyverse)
library(here)
library(glue)
library(sf)
library(rajudas)
library(jsonlite)
# path to segment data ----------------------------------------------------
path_data_segments = here("output/data/dw/full_area_analysis/per_segment_mean_diff_ratio.geojson")
# data per segment ---------------------------------------------------------
data_per_segment = read_sf(path_data_segments)
# -------------------------------------------------------------------------
# per street level
# -------------------------------------------------------------------------
data_per_segment %>%
group_by(streetName) %>%
summarise(
mean_diff = weighted.mean(mean_diff, distance, na.rm = T),
mean_ratio = weighted.mean(mean_ratio, distance, na.rm =
T),
mean_sample_size = mean(sampleSize_avg)
) -> mean_per_street
# per street or per segment! ----------------------------------------------
data = data_per_segment
# n classes
n_stops = 9
# colors
colors = scico::scico(n_stops+2, palette="vik") %>% rev()
colors[6] = "lightgrey"
# variable for binning the data
var = "mean_ratio"
#  equally spaced bins
data_extent = c(min(data[[var]], na.rm=T), max(data[[var]], na.rm=T))
data_extent_min = -max(abs(round(data_extent)))
data_extent_max = max(abs(round(data_extent)))
breaks = seq(from=0.5, to=1.5, length.out=n_stops + 1)
# labels
labels = imap_chr(breaks, function(., idx) {
paste0(round(breaks[idx],1), " - ", round(breaks[idx + 1],1))
}) %>% .[1:length(.) - 1]
first_label = " < -0.5"
last_label = "> 1.5"
labels = c(first_label, labels, last_label)
# assign data to classes
data %>%
filter(if_all({{var}}, ~!is.na(.x))) %>%
mutate(
class = findInterval(!!sym(var), breaks),
classname = labels[class+1],
color = colors[class+1]
) %>%
group_by(class, classname, color) %>%
summarise() %>%
mutate("stroke-width" = 2.5) -> data_colored
library(rmapshaper)
data_dw_simp = data_colored %>% ms_simplify()
op = makePath(here("output/data/dw/full_area_analysis/overview_mean_ratio_street_per_class.geojson"))
unlink(op)
write_sf(data_dw_simp, op)
